# Design: Deterministic Workflow Layer

## Problem

When a user triggers market analysis, the system immediately runs all 4 CrewAI agents (~4 minutes, ~50k tokens) with no upfront visibility or direction. The user has no chance to refine the scope, and the agent researches broadly rather than targeting what the user actually needs. If the user has previously explored startup ideas, that context is lost.

## Solution

A workflow orchestrator that enforces three mandatory phases before any research executes:

1. **Clarify** - Generate 2-3 targeted clarifying questions using a lightweight LLM call (Haiku). This narrows the research direction before spending time and tokens.
2. **Plan** - Generate a concrete research plan based on the user's answers. Present it for approval so the user knows exactly what will happen.
3. **Execute** - Only after approval, run the CrewAI agents with the refined scope.

This makes the agent ~10% deterministic: it never dives into expensive research blindly.

## Architecture

```
                    ┌──────────────────────┐
                    │   User / API Layer   │
                    └──────────┬───────────┘
                               │
                    ┌──────────▼───────────┐
                    │  WorkflowOrchestrator │  (new)
                    │  ┌─────────────────┐ │
                    │  │  Phase: Clarify  │ │ ← Haiku generates questions
                    │  │  Phase: Plan     │ │ ← Haiku generates research plan
                    │  │  Phase: Execute  │ │ ← Delegates to CrewAI
                    │  └─────────────────┘ │
                    └──────────┬───────────┘
                               │
              ┌────────────────┼────────────────┐
              │                │                │
   ┌──────────▼──────┐  ┌─────▼──────┐  ┌──────▼─────────┐
   │ StartupContext   │  │ LLM (Haiku)│  │ SimpleMarket   │
   │ Store            │  │ (clarify + │  │ Crew           │
   │ (past ideas)     │  │  plan gen) │  │ (4 agents)     │
   └─────────────────┘  └────────────┘  └────────────────┘
```

## State Machine

```
start(user_id, message)
  ├─ Retrieve existing startups from StartupContextStore
  ├─ Use Haiku to generate 2-3 clarifying questions
  │   (includes "which startup?" if multiple exist)
  └─ Return state: phase="clarify", questions=[...]

answer_questions(workflow_id, answers)
  ├─ Feed user_message + answers into Haiku
  ├─ Generate structured research plan (search terms, scope, focus areas)
  └─ Return state: phase="plan", plan={...}

approve_plan(workflow_id)
  ├─ Run SimpleMarketCrew.analyze_market() with refined params
  └─ Return state: phase="completed", results={...}

reject_plan(workflow_id)
  └─ Return state: phase="cancelled"
```

## Data Model

### WorkflowPhase (enum)
- `clarify` - Waiting for user to answer clarifying questions
- `plan` - Waiting for user to approve research plan
- `execute` - Running CrewAI agents
- `completed` - Done, results available
- `cancelled` - User rejected the plan

### StartupContext (dataclass)
Represents a previously stored startup idea:
- `id`, `user_id`, `name`, `description`
- `industry`, `search_terms`, `geographical_scope`
- `created_at`, `last_accessed`, `metadata`

### ClarifyingQuestion (dataclass)
A question generated by the LLM:
- `question` - The question text
- `context` - Why this question matters for focusing the research

### ResearchPlan (dataclass)
The plan presented to the user before execution:
- `title` - e.g., "B2B Generative AI for Legal - Texas Market Analysis"
- `steps` - List of ResearchPlanStep (name, description, agent_role, estimated_duration)
- `search_terms` - Refined search terms based on clarification
- `geographical_scope` - Target geography
- `focus_areas` - Specific areas to investigate
- `estimated_duration`, `estimated_cost`

### WorkflowState (dataclass)
Full state of a workflow instance:
- `workflow_id`, `phase`, `user_message`
- `clarifying_questions`, `user_answers`
- `plan`, `results`, `startup_context`

## Contracts (Abstract Interfaces)

### StartupContextStore (ABC)
```python
async def get_user_startups(user_id: str) -> List[StartupContext]
async def get_startup_by_id(startup_id: str) -> Optional[StartupContext]
async def save_startup(context: StartupContext) -> str
```

### WorkflowOrchestrator (ABC)
```python
async def start(user_id: str, user_message: str) -> WorkflowState
async def answer_questions(workflow_id: str, answers: Dict[str, str]) -> WorkflowState
async def approve_plan(workflow_id: str) -> WorkflowState
async def reject_plan(workflow_id: str) -> WorkflowState
async def get_state(workflow_id: str) -> WorkflowState
```

## Default Implementations

### DefaultOrchestrator
- Uses Haiku LLM (same config as existing agents) for question + plan generation
- In-memory workflow state storage (white-label overrides for persistence)
- Wraps `SimpleMarketCrew.analyze_market()` for execution
- Two key LLM prompts:
  - `_generate_questions()` - System prompt instructs Haiku to analyze the user's message and output 2-3 clarifying questions as JSON
  - `_generate_plan()` - System prompt instructs Haiku to take the original message + answers and produce a structured research plan as JSON

### FileContextStore
- JSON file-based storage: `{storage_dir}/{user_id}/{startup_id}.json`
- Suitable for development/testing
- White-label implementations replace with database-backed stores

## End-to-End Example

```python
from desilo_core.workflow import DefaultOrchestrator, FileContextStore

store = FileContextStore("./data/startups")
orchestrator = DefaultOrchestrator(context_store=store)

# Phase 1: Start - get clarifying questions
state = await orchestrator.start("user_123", "I want to explore the AI market")
# state.phase == "clarify"
# state.clarifying_questions == [
#   ClarifyingQuestion("Are you targeting B2B enterprise or B2C?", "Determines market sizing approach"),
#   ClarifyingQuestion("Any specific AI vertical?", "Focuses competitive analysis"),
#   ClarifyingQuestion("What geography?", "Scopes local resources and regulations"),
# ]

# Phase 2: Answer - get research plan
state = await orchestrator.answer_questions(state.workflow_id, {
    "q1": "B2B enterprise",
    "q2": "Generative AI for legal",
    "q3": "US market, starting in Texas"
})
# state.phase == "plan"
# state.plan.title == "B2B Generative AI for Legal - Texas/US Market Analysis"
# state.plan.search_terms == ["generative AI legal", "legaltech AI", ...]
# state.plan.steps == [4 research steps with descriptions]

# Phase 3: Approve - execute research
state = await orchestrator.approve_plan(state.workflow_id)
# state.phase == "completed"
# state.results == { full market analysis from CrewAI }
```

## File Manifest

| Action | File | Purpose |
|--------|------|---------|
| CREATE | `desilo_core/contracts/workflow.py` | ABCs and dataclasses for workflow layer |
| CREATE | `desilo_core/workflow/__init__.py` | Package init |
| CREATE | `desilo_core/workflow/orchestrator.py` | DefaultOrchestrator state machine |
| CREATE | `desilo_core/workflow/context_store.py` | FileContextStore (JSON filesystem) |
| CREATE | `tests/test_workflow.py` | Unit tests (mocked LLM + crew) |
| MODIFY | `desilo_core/contracts/__init__.py` | Export workflow contracts |
| MODIFY | `desilo_core/contracts/tenant.py` | Add enable_workflow_approval flag |

## Design Decisions

1. **LLM-generated questions over templates** - Templates would always ask the same generic questions. Haiku can analyze the user's specific message and ask targeted questions, skipping what's already clear.

2. **Plan is descriptive, not executable** - The plan steps are for user visibility. Execution still calls `SimpleMarketCrew.analyze_market()` as one unit. Per-step execution would over-engineer the current 4-agent crew.

3. **In-memory state** - Sufficient for single-process use. White-label deployments that need persistence (web APIs, multi-request flows) override the storage mechanism.

4. **Orchestrator wraps, doesn't modify agents** - No changes to SimpleMarketCrew or BaseResearchCrew. The orchestrator composes around them, keeping the agent layer clean.

5. **Filesystem context store as default** - Matches the existing CollaborativeMemory pattern. Production deployments use database-backed implementations.

## Testing Strategy

- Mock LLM calls to return predetermined questions and plans
- Mock `SimpleMarketCrew.analyze_market` to avoid API costs
- Test all state transitions: start -> clarify -> plan -> approve -> completed
- Test edge cases: rejection, existing startups, single startup auto-context
- No API keys required for unit tests
